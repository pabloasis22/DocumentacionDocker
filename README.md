# Gu√≠a Profesional de Docker Compose
## Arquitectura Contenedorizada: React + FastAPI + PostgreSQL

**Versi√≥n:** 2.0  
**Fecha:** 26/02/2026  
**Stack:** React 18+ ¬∑ FastAPI 0.100+ ¬∑ PostgreSQL 16 ¬∑ Docker Compose v2

---

## Tabla de Contenidos

1. [Fundamentos T√©cnicos](#1-fundamentos-t√©cnicos)
2. [Arquitectura del Sistema](#2-arquitectura-del-sistema)
3. [Estructura Profesional del Proyecto](#3-estructura-profesional-del-proyecto)
4. [Dockerizaci√≥n del Frontend (React)](#4-dockerizaci√≥n-del-frontend-react)
5. [Dockerizaci√≥n del Backend (FastAPI)](#5-dockerizaci√≥n-del-backend-fastapi)
6. [Servicio PostgreSQL](#6-servicio-postgresql)
7. [docker-compose.yml Profesional](#7-docker-composeyml-profesional)
8. [Comunicaci√≥n entre Servicios](#8-comunicaci√≥n-entre-servicios)
9. [Modo Desarrollo vs Producci√≥n](#9-modo-desarrollo-vs-producci√≥n)
10. [Seguridad y Buenas Pr√°cticas](#10-seguridad-y-buenas-pr√°cticas)
11. [Automatizaci√≥n y DevOps](#11-automatizaci√≥n-y-devops)
12. [Problemas Reales y Troubleshooting](#12-problemas-reales-y-troubleshooting)

---

# 1. Fundamentos T√©cnicos

## 1.1 ¬øQu√© es Docker?

Docker es una plataforma de contenedorizaci√≥n que empaqueta aplicaciones y todas sus dependencias en unidades aisladas llamadas **contenedores**. A diferencia de las m√°quinas virtuales, los contenedores comparten el kernel del sistema operativo host, lo que los hace extremadamente ligeros y r√°pidos de iniciar.

La raz√≥n fundamental por la que Docker transform√≥ la industria no es simplemente "empaquetar aplicaciones", sino que **elimina la divergencia entre entornos**. El cl√°sico problema "en mi m√°quina funciona" desaparece porque el contenedor ES el entorno. Un contenedor construido en tu laptop de desarrollo se comporta de manera id√©ntica en un servidor de producci√≥n en AWS.

Docker utiliza internamente tecnolog√≠as del kernel Linux: **namespaces** para el aislamiento de procesos, **cgroups** para la limitaci√≥n de recursos, y **union filesystems** (OverlayFS) para la gesti√≥n eficiente de capas de imagen.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              M√ÅQUINA VIRTUAL                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  App A   ‚îÇ  ‚îÇ  App B   ‚îÇ  ‚îÇ  App C   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Bins/   ‚îÇ  ‚îÇ  Bins/   ‚îÇ  ‚îÇ  Bins/   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Libs    ‚îÇ  ‚îÇ  Libs    ‚îÇ  ‚îÇ  Libs    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Guest OS ‚îÇ  ‚îÇ Guest OS ‚îÇ  ‚îÇ Guest OS ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ           HYPERVISOR                 ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ            HOST OS                   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CONTENEDORES                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  App A   ‚îÇ  ‚îÇ  App B   ‚îÇ  ‚îÇ  App C   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Bins/   ‚îÇ  ‚îÇ  Bins/   ‚îÇ  ‚îÇ  Bins/   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Libs    ‚îÇ  ‚îÇ  Libs    ‚îÇ  ‚îÇ  Libs    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ         DOCKER ENGINE                ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ            HOST OS                   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Decisi√≥n arquitect√≥nica:** Usamos contenedores en lugar de VMs porque nuestro stack (React + FastAPI + PostgreSQL) no necesita aislamiento a nivel de kernel. Los contenedores ofrecen arranque en milisegundos, menor consumo de memoria y mayor densidad de servicios por host.

## 1.2 ¬øQu√© es Docker Compose?

Docker Compose es una herramienta de **orquestaci√≥n declarativa** para definir y ejecutar aplicaciones multi-contenedor. En lugar de ejecutar m√∫ltiples comandos `docker run` con decenas de flags, se declara el estado deseado del sistema en un archivo YAML (`docker-compose.yml`), y Compose se encarga de materializarlo.

Compose resuelve tres problemas fundamentales:

1. **Orquestaci√≥n de dependencias:** Define el orden de arranque y las relaciones entre servicios (la base de datos debe estar lista antes de que el backend intente conectarse).
2. **Gesti√≥n de red:** Crea autom√°ticamente una red interna donde los servicios se descubren por nombre DNS.
3. **Reproducibilidad:** Un solo archivo describe todo el sistema. Cualquier ingeniero puede levantar el entorno completo con `docker compose up`.

**Versi√≥n importante:** Docker Compose v2 (integrado como plugin de Docker CLI: `docker compose`) reemplaza a la v1 (el binario independiente `docker-compose`). En esta gu√≠a usamos **Compose v2** exclusivamente. La diferencia no es solo sint√°ctica: v2 tiene mejor rendimiento, soporte nativo para BuildKit, y profiles.

## 1.3 Im√°genes vs Contenedores

Esta distinci√≥n es **crucial** y frecuentemente malentendida:

| Concepto | Analog√≠a | Descripci√≥n |
|----------|----------|-------------|
| **Imagen** | Clase (OOP) | Template inmutable de solo lectura. Compuesto por capas ordenadas. |
| **Contenedor** | Instancia (OOP) | Proceso en ejecuci√≥n creado a partir de una imagen. Tiene estado mutable. |

```
IMAGEN (inmutable, capas de solo lectura)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Capa 5: COPY app/ .    ‚îÇ  ‚Üê Tu c√≥digo
‚îÇ  Capa 4: RUN pip install‚îÇ  ‚Üê Dependencias
‚îÇ  Capa 3: RUN apt-get    ‚îÇ  ‚Üê Paquetes del SO
‚îÇ  Capa 2: ENV PYTHONPATH  ‚îÇ  ‚Üê Variables
‚îÇ  Capa 1: python:3.12-slim‚îÇ  ‚Üê Imagen base
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚îÇ  docker run / docker compose up
         ‚ñº
CONTENEDOR (capa de escritura ef√≠mera)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Capa R/W: logs, tmp,   ‚îÇ  ‚Üê Escritura temporal
‚îÇ  pid files, sockets     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Capas de imagen (R/O)  ‚îÇ  ‚Üê Compartidas entre contenedores
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Por qu√© esto importa en producci√≥n:** Las capas se comparten entre contenedores. Si tienes 10 contenedores basados en `python:3.12-slim`, la imagen base se almacena una sola vez en disco. Docker utiliza Copy-on-Write (CoW): un contenedor solo consume espacio adicional cuando escribe datos nuevos. Esto es lo que permite ejecutar cientos de contenedores en un solo host.

**Implicaci√≥n pr√°ctica:** Cada instrucci√≥n en un Dockerfile crea una capa. El orden de las instrucciones afecta directamente al cach√© de build. Las instrucciones que cambian con menor frecuencia deben ir primero (instalar dependencias del SO), y las que cambian con mayor frecuencia al final (copiar c√≥digo fuente). Esto reduce dr√°sticamente los tiempos de build.

## 1.4 Networking Interno de Docker

Docker crea redes virtuales que permiten la comunicaci√≥n entre contenedores. Existen varios drivers de red:

| Driver | Uso | Aislamiento |
|--------|-----|-------------|
| `bridge` | Red privada por defecto. Contenedores en la misma red se comunican. | Medio |
| `host` | El contenedor usa la red del host directamente. | Ninguno |
| `none` | Sin conectividad de red. | Total |
| `overlay` | Redes multi-host (Docker Swarm). | Alto |

**En Docker Compose**, se crea autom√°ticamente una red bridge personalizada para cada proyecto. El nombre sigue la convenci√≥n `{nombre_proyecto}_default`. Dentro de esta red:

```
Red Docker: myproject_default (172.18.0.0/16)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ frontend ‚îÇ    ‚îÇ backend  ‚îÇ    ‚îÇ    db     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ172.18.0.2‚îÇ    ‚îÇ172.18.0.3‚îÇ    ‚îÇ172.18.0.4‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  :3000   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  :8000   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  :5432   ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                  ‚îÇ
‚îÇ  DNS interno resuelve nombres de servicio:       ‚îÇ
‚îÇ  "backend" ‚Üí 172.18.0.3                         ‚îÇ
‚îÇ  "db"      ‚Üí 172.18.0.4                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ports: "3000:3000"  (solo frontend expuesto al host)
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   HOST / Usuario ‚îÇ
‚îÇ   localhost:3000 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Decisi√≥n cr√≠tica: redes personalizadas vs red por defecto.** Siempre debemos definir redes expl√≠citas en producci√≥n. La red `default` funciona, pero las redes personalizadas permiten segmentaci√≥n: el frontend no necesita acceso directo a la base de datos. Esto implementa el **principio de menor privilegio** a nivel de red.

## 1.5 Vol√∫menes

Los contenedores son **ef√≠meros** por dise√±o. Cuando un contenedor se destruye, todos los datos escritos en su capa de escritura desaparecen. Los vol√∫menes resuelven esto proporcionando almacenamiento persistente.

Existen tres mecanismos principales:

### Named Volumes (Vol√∫menes con nombre)
Gestionados completamente por Docker. Son la opci√≥n recomendada para persistencia en producci√≥n.

```yaml
volumes:
  postgres_data:  # Docker gestiona la ubicaci√≥n en disco

services:
  db:
    volumes:
      - postgres_data:/var/lib/postgresql/data
```

Los datos se almacenan en `/var/lib/docker/volumes/postgres_data/_data` en el host. Docker controla los permisos y el ciclo de vida.

### Bind Mounts (Montajes de enlace)
Mapean un directorio del host directamente al contenedor. Esenciales para desarrollo (hot reload), pero problem√°ticos en producci√≥n por acoplamiento al filesystem del host.

```yaml
services:
  backend:
    volumes:
      - ./backend/app:/app  # Directorio local ‚Üí contenedor
```

### tmpfs Mounts
Almacenamiento en memoria RAM. √ötil para datos temporales sensibles que no deben persistir en disco (tokens, cach√© de sesiones).

```yaml
services:
  backend:
    tmpfs:
      - /tmp
```

**Decisi√≥n para nuestro sistema:**
- PostgreSQL ‚Üí Named volume (`postgres_data`). Los datos de la BD DEBEN persistir entre reinicios.
- Backend en desarrollo ‚Üí Bind mount para hot reload del c√≥digo.
- Backend en producci√≥n ‚Üí Sin bind mount. El c√≥digo va dentro de la imagen.
- Frontend en desarrollo ‚Üí Bind mount para hot reload.
- Frontend en producci√≥n ‚Üí Imagen est√°tica con Nginx. Sin vol√∫menes.

## 1.6 Ciclo de Vida de Servicios

Comprender el ciclo de vida es fundamental para diagnosticar problemas:

```
    docker compose up
          ‚îÇ
          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CREATED       ‚îÇ  Contenedor creado, no iniciado
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   RUNNING       ‚îÇ  Proceso principal ejecut√°ndose
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         ‚îÇ
    ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PAUSED ‚îÇ ‚îÇ  EXITED    ‚îÇ  Proceso termin√≥ (c√≥digo 0 o error)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ
                  ‚ñº
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ  REMOVED    ‚îÇ  docker compose down
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Restart policies** controlan qu√© ocurre cuando un contenedor se detiene:

| Policy | Comportamiento |
|--------|----------------|
| `no` | No reiniciar nunca (defecto) |
| `always` | Reiniciar siempre, incluyendo al iniciar Docker daemon |
| `on-failure` | Reiniciar solo si el proceso sale con c√≥digo != 0 |
| `unless-stopped` | Como `always`, pero no reiniciar si fue detenido manualmente |

**Recomendaci√≥n de producci√≥n:** Usar `unless-stopped` para servicios como PostgreSQL y el backend. Esto sobrevive a reinicios del servidor, pero respeta paradas manuales para mantenimiento.

---

# 2. Arquitectura del Sistema

## 2.1 Visi√≥n General

```
                    INTERNET
                       ‚îÇ
                       ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   NAVEGADOR    ‚îÇ
              ‚îÇ   (Usuario)    ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ  HTTP :80 / :443
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DOCKER HOST                           ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ Red: frontend_net ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ                                                 ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ     FRONTEND         ‚îÇ                       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ                       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ    Nginx       ‚îÇ   ‚îÇ                       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  (puerto 80)   ‚îÇ   ‚îÇ                       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  Sirve React   ‚îÇ   ‚îÇ                       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  build est√°tico‚îÇ   ‚îÇ                       ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  + proxy_pass  ‚îÇ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ /api/* ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ               ‚îÇ     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                          ‚îÇ     ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                              ‚îÇ           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ Red: backend_net ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ                                          ‚îÇ     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ      BACKEND         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ   Uvicorn     ‚îÇ   ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  (puerto 8000) ‚îÇ   ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ   FastAPI      ‚îÇ   ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ postgresql://db:5432/appdb        ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ             ‚ñº                                   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ     POSTGRESQL       ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  postgres 16  ‚îÇ   ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ (puerto 5432) ‚îÇ   ‚îÇ   Sin exposici√≥n     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  SOLO interno ‚îÇ   ‚îÇ   al host            ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  üìÅ Volume:          ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  postgres_data       ‚îÇ                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                                                 ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## 2.2 Separaci√≥n de Servicios y Responsabilidades

Cada servicio tiene una responsabilidad √∫nica y bien definida:

**Frontend (React + Nginx):**
- Servir la aplicaci√≥n SPA (Single Page Application) como archivos est√°ticos.
- Actuar como **reverse proxy** hacia el backend para las rutas `/api/*`.
- Manejar compresi√≥n gzip, cach√© de assets est√°ticos, y TLS termination.
- En producci√≥n, Nginx es el √∫nico punto de entrada desde Internet.

**Backend (FastAPI + Uvicorn):**
- Exponer la API REST/GraphQL.
- Ejecutar la l√≥gica de negocio.
- Gestionar autenticaci√≥n, autorizaci√≥n, y validaci√≥n.
- Conectarse a PostgreSQL para operaciones CRUD.
- Ejecutar migraciones de esquema de base de datos (Alembic).

**Base de Datos (PostgreSQL):**
- Almacenamiento persistente de datos.
- Integridad transaccional (ACID).
- No se expone fuera de la red Docker. Nunca.

**Justificaci√≥n de la arquitectura de dos redes:**

Se utilizan dos redes Docker (`frontend_net` y `backend_net`) en lugar de una sola. El backend pertenece a ambas redes, actuando como puente. El frontend NO puede comunicarse directamente con PostgreSQL. Esto aplica el principio de **defensa en profundidad**: si el contenedor frontend es comprometido, el atacante no tiene ruta de red hacia la base de datos.

## 2.3 Flujo de Comunicaci√≥n

**Petici√≥n t√≠pica del usuario:**

```
1. Usuario abre http://miapp.com
   ‚Üí Nginx sirve index.html + bundle JS de React

2. React hace fetch("/api/users")
   ‚Üí Nginx intercepta /api/* y hace proxy_pass a http://backend:8000

3. FastAPI recibe GET /users
   ‚Üí SQLAlchemy ejecuta SELECT * FROM users
   ‚Üí Conexi√≥n a postgresql://db:5432/appdb

4. PostgreSQL retorna resultados
   ‚Üí FastAPI serializa con Pydantic
   ‚Üí Nginx retorna JSON al navegador
   ‚Üí React renderiza los datos
```

**Decisi√≥n de dise√±o: Nginx como proxy.** Aunque React podr√≠a hacer peticiones directamente a `http://backend:8000`, esto crea problemas de CORS y expone el backend al exterior. Usar Nginx como proxy unifica todo bajo un solo dominio, eliminando CORS y simplificando TLS.

---

# 3. Estructura Profesional del Proyecto

```
project/
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                # Build de la imagen React
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.dev            # Imagen para desarrollo con hot reload
‚îÇ   ‚îú‚îÄ‚îÄ nginx/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ default.conf          # Configuraci√≥n de Nginx para producci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ package-lock.json
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js            # Cliente HTTP configurado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pages/
‚îÇ   ‚îî‚îÄ‚îÄ .dockerignore
‚îÇ
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                # Build de la imagen FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.dev            # Imagen para desarrollo
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt          # Dependencias Python pinned
‚îÇ   ‚îú‚îÄ‚îÄ requirements-dev.txt      # Dependencias adicionales de desarrollo
‚îÇ   ‚îú‚îÄ‚îÄ alembic.ini               # Configuraci√≥n de migraciones
‚îÇ   ‚îú‚îÄ‚îÄ alembic/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ env.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ versions/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py               # Punto de entrada FastAPI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py             # Configuraci√≥n centralizada (Pydantic Settings)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py           # Engine y Session de SQLAlchemy
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/               # Modelos ORM
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/              # Esquemas Pydantic
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ user.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routers/              # Endpoints agrupados
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ users.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/             # L√≥gica de negocio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ middleware/
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_users.py
‚îÇ   ‚îî‚îÄ‚îÄ .dockerignore
‚îÇ
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ init/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 01-init.sql           # Script SQL de inicializaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ backups/                  # Directorio para dumps
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ start-dev.sh              # Arranque modo desarrollo
‚îÇ   ‚îú‚îÄ‚îÄ start-prod.sh             # Arranque modo producci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ backup-db.sh              # Script de backup PostgreSQL
‚îÇ   ‚îî‚îÄ‚îÄ wait-for-it.sh            # Script para esperar servicios
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml            # Configuraci√≥n base
‚îú‚îÄ‚îÄ docker-compose.dev.yml        # Override para desarrollo
‚îú‚îÄ‚îÄ docker-compose.prod.yml       # Override para producci√≥n
‚îú‚îÄ‚îÄ .env                          # Variables de entorno (NO commitear)
‚îú‚îÄ‚îÄ .env.example                  # Template de variables
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ Makefile                      # Comandos simplificados
‚îî‚îÄ‚îÄ README.md
```

## 3.1 Justificaci√≥n de la Estructura

**Separaci√≥n por servicio:** Cada servicio tiene su propio directorio con su Dockerfile. Esto permite builds independientes, versionado separado, y la posibilidad de que diferentes equipos trabajen en paralelo sin conflictos.

**Dockerfiles separados (dev/prod):** En lugar de un solo Dockerfile con targets multi-stage para todo, tener `Dockerfile` (producci√≥n) y `Dockerfile.dev` (desarrollo) simplifica la lectura y evita errores al construir la imagen incorrecta. Algunos equipos prefieren un √∫nico Dockerfile con `--target`; ambos enfoques son v√°lidos. Aqu√≠ priorizamos claridad.

**docker-compose override pattern:** Docker Compose soporta archivos de override. Al ejecutar `docker compose -f docker-compose.yml -f docker-compose.dev.yml up`, el segundo archivo sobrescribe o extiende al primero. Esto permite una base compartida con variaciones por entorno. Es el patr√≥n recomendado oficialmente.

**Directorio `scripts/`:** Scripts de shell para automatizaci√≥n. Un `Makefile` o `justfile` en la ra√≠z proporciona una interfaz unificada (`make dev`, `make prod`, `make backup`).

**`.env.example`:** Se commitea al repositorio como documentaci√≥n de qu√© variables son necesarias. El `.env` real con credenciales se excluye del control de versiones.

---

# 4. Dockerizaci√≥n del Frontend (React)

## 4.1 Dockerfile de Producci√≥n (Multi-Stage Build)

```dockerfile
# ============================================================
# frontend/Dockerfile ‚Äî Producci√≥n
# Multi-stage build: Node (build) ‚Üí Nginx (serve)
# ============================================================

# ‚îÄ‚îÄ Stage 1: Build ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FROM node:20-alpine AS builder

# Crear usuario no-root para el build
RUN addgroup -S appgroup && adduser -S appuser -G appgroup

WORKDIR /app

# Copiar SOLO archivos de dependencias primero (cach√© de capas)
COPY package.json package-lock.json ./

# Instalar dependencias con ci (m√°s r√°pido y determinista que npm install)
RUN npm ci --only=production=false

# Ahora copiar el c√≥digo fuente
COPY . .

# Argumento de build para la URL del API
# Se inyecta en build time porque React embebe las variables en el bundle
ARG VITE_API_URL=/api
ENV VITE_API_URL=${VITE_API_URL}

# Generar build de producci√≥n
RUN npm run build

# ‚îÄ‚îÄ Stage 2: Serve ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FROM nginx:1.27-alpine AS production

# Eliminar configuraci√≥n default de Nginx
RUN rm /etc/nginx/conf.d/default.conf

# Copiar configuraci√≥n personalizada
COPY nginx/default.conf /etc/nginx/conf.d/default.conf

# Copiar build est√°tico desde el stage anterior
COPY --from=builder /app/dist /usr/share/nginx/html

# Crear usuario no-root para Nginx
RUN chown -R nginx:nginx /usr/share/nginx/html && \
    chown -R nginx:nginx /var/cache/nginx && \
    chown -R nginx:nginx /var/log/nginx && \
    touch /var/run/nginx.pid && \
    chown -R nginx:nginx /var/run/nginx.pid

# Exponer puerto 80 (documentaci√≥n, no funcional)
EXPOSE 80

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost:80/health || exit 1

# Ejecutar como no-root
USER nginx

CMD ["nginx", "-g", "daemon off;"]
```

## 4.2 Justificaci√≥n T√©cnica del Multi-Stage Build

El multi-stage build es **obligatorio** para producci√≥n por tres razones:

1. **Tama√±o de imagen:** La imagen de Node con `node_modules` puede pesar 1-2 GB. La imagen final con solo Nginx + archivos est√°ticos pesa ~25 MB. Esto reduce dr√°sticamente el tiempo de deploy y la superficie de ataque.

2. **Seguridad:** La imagen final no contiene Node.js, npm, c√≥digo fuente, ni dependencias de desarrollo. Un atacante que comprometa el contenedor frontend solo tiene acceso a archivos HTML/CSS/JS est√°ticos y al binario de Nginx.

3. **Cach√© de capas:** Al copiar `package.json` y `package-lock.json` antes del c√≥digo fuente, Docker reutiliza la capa de `npm ci` mientras las dependencias no cambien. Esto reduce builds de 3-5 minutos a segundos cuando solo cambia c√≥digo.

## 4.3 Configuraci√≥n de Nginx

```nginx
# frontend/nginx/default.conf

# Configuraci√≥n upstream del backend
upstream backend_api {
    server backend:8000;
    # Si tuvieras m√∫ltiples replicas:
    # server backend-1:8000;
    # server backend-2:8000;
}

server {
    listen 80;
    server_name _;

    root /usr/share/nginx/html;
    index index.html;

    # ‚îÄ‚îÄ Compresi√≥n gzip ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types
        text/plain
        text/css
        text/javascript
        application/javascript
        application/json
        application/xml
        image/svg+xml;

    # ‚îÄ‚îÄ Cach√© de assets est√°ticos ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
        try_files $uri =404;
    }

    # ‚îÄ‚îÄ Proxy hacia el backend ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    location /api/ {
        proxy_pass http://backend_api/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        # Timeouts
        proxy_connect_timeout 30s;
        proxy_send_timeout 30s;
        proxy_read_timeout 60s;

        # WebSocket support (si usas conexiones en tiempo real)
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }

    # ‚îÄ‚îÄ Health check endpoint ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }

    # ‚îÄ‚îÄ SPA: todas las rutas a index.html ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    location / {
        try_files $uri $uri/ /index.html;
    }

    # ‚îÄ‚îÄ Seguridad: ocultar versi√≥n de Nginx ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    server_tokens off;

    # ‚îÄ‚îÄ Headers de seguridad ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;
}
```

**`try_files $uri $uri/ /index.html`:** Esta directiva es cr√≠tica para SPAs. Cuando el usuario navega a `/users/123`, Nginx primero busca un archivo literal `/users/123`. Al no encontrarlo, sirve `index.html`, y React Router maneja la ruta en el cliente.

**`proxy_pass http://backend_api/`:** La barra final es importante. Con `proxy_pass http://backend_api/`, una petici√≥n a `/api/users` se reenv√≠a como `/users` al backend. Sin la barra, se reenviar√≠a como `/api/users`.

## 4.4 Dockerfile de Desarrollo

```dockerfile
# ============================================================
# frontend/Dockerfile.dev ‚Äî Desarrollo con Hot Reload
# ============================================================
FROM node:20-alpine

WORKDIR /app

# Instalar dependencias primero para cach√©
COPY package.json package-lock.json ./
RUN npm ci

# El c√≥digo se monta como bind mount, no se copia
# COPY . .  ‚Üê NO hacer esto en desarrollo

EXPOSE 5173

# Vite dev server con hot reload
CMD ["npm", "run", "dev", "--", "--host", "0.0.0.0"]
```

**¬øPor qu√© no copiar c√≥digo en desarrollo?** Porque usamos bind mounts. El directorio `./frontend/src` del host se monta en `/app/src` del contenedor. Cuando guardas un archivo, Vite detecta el cambio y recarga el navegador instant√°neamente. Copiar el c√≥digo al build har√≠a que los cambios no se reflejen hasta reconstruir la imagen.

## 4.5 .dockerignore del Frontend

```
# frontend/.dockerignore
node_modules
dist
build
.git
.gitignore
.env
.env.*
*.md
.vscode
.idea
coverage
```

**Crucial:** Incluir `node_modules` en `.dockerignore`. Sin esto, Docker copiar√≠a los `node_modules` del host (que pueden tener binarios compilados para tu SO) al contenedor (Linux Alpine). Esto causa errores cr√≠pticos de m√≥dulos nativos. Las dependencias deben instalarse siempre DENTRO del contenedor.

---

# 5. Dockerizaci√≥n del Backend (FastAPI)

## 5.1 Dockerfile de Producci√≥n

```dockerfile
# ============================================================
# backend/Dockerfile ‚Äî Producci√≥n
# ============================================================
FROM python:3.12-slim AS base

# Prevenir creaci√≥n de .pyc y buffering de stdout
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    # Pip
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Instalar dependencias del sistema necesarias para psycopg2
# (compilador C y headers de PostgreSQL)
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        libpq-dev \
        curl \
    && rm -rf /var/lib/apt/lists/*

# Crear usuario no-root
RUN groupadd -r appuser && useradd -r -g appuser -d /app -s /sbin/nologin appuser

WORKDIR /app

# ‚îÄ‚îÄ Stage: Dependencies ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FROM base AS dependencies

# Copiar solo requirements para cach√© de dependencias
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ‚îÄ‚îÄ Stage: Production ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FROM dependencies AS production

# Copiar c√≥digo de la aplicaci√≥n
COPY ./app ./app
COPY ./alembic ./alembic
COPY ./alembic.ini .

# Asignar propiedad al usuario no-root
RUN chown -R appuser:appuser /app

# Cambiar a usuario no-root
USER appuser

# Puerto de la aplicaci√≥n
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Gunicorn con workers Uvicorn para producci√≥n
# Workers = (2 √ó CPU cores) + 1
CMD ["gunicorn", "app.main:app", \
     "--worker-class", "uvicorn.workers.UvicornWorker", \
     "--workers", "4", \
     "--bind", "0.0.0.0:8000", \
     "--access-logfile", "-", \
     "--error-logfile", "-", \
     "--timeout", "120", \
     "--graceful-timeout", "30", \
     "--keep-alive", "5"]
```

## 5.2 Decisiones T√©cnicas Explicadas

### Uvicorn vs Gunicorn en producci√≥n

**Uvicorn** es un servidor ASGI de alto rendimiento basado en uvloop. Es excelente para desarrollo, pero en producci√≥n tiene una limitaci√≥n: es single-process. Si el proceso muere, el servicio cae.

**Gunicorn** es un process manager probado en batalla. Al combinarlo con workers de tipo `UvicornWorker`, obtenemos lo mejor de ambos mundos: Gunicorn gestiona m√∫ltiples procesos worker (reinicio autom√°tico si un worker muere, distribuci√≥n de carga), y cada worker ejecuta Uvicorn para manejar peticiones ASGI.

```
Gunicorn (master)
‚îú‚îÄ‚îÄ UvicornWorker 1 (PID 10) ‚Üê Maneja requests async
‚îú‚îÄ‚îÄ UvicornWorker 2 (PID 11) ‚Üê Maneja requests async
‚îú‚îÄ‚îÄ UvicornWorker 3 (PID 12) ‚Üê Maneja requests async
‚îî‚îÄ‚îÄ UvicornWorker 4 (PID 13) ‚Üê Maneja requests async
```

**F√≥rmula de workers:** `(2 √ó n√∫cleos_CPU) + 1`. Para un contenedor con 2 CPU asignadas: 5 workers. M√°s workers no siempre es mejor; cada uno consume ~50-100 MB de RAM.

### `PYTHONUNBUFFERED=1`

Sin esta variable, Python bufferiza la salida est√°ndar. En un contenedor, esto significa que los logs no aparecen en `docker compose logs` hasta que el buffer se llena. Con `PYTHONUNBUFFERED=1`, cada l√≠nea de log aparece inmediatamente. Indispensable para debugging y monitoreo.

### `PYTHONDONTWRITEBYTECODE=1`

Previene la creaci√≥n de archivos `.pyc`. En un contenedor de producci√≥n, estos archivos solo ocupan espacio en la capa de escritura sin beneficio de rendimiento significativo (el contenedor se destruye y recrea con cada deploy).

## 5.3 requirements.txt (Dependencias Pinned)

```
# backend/requirements.txt
# SIEMPRE versiones pinned para reproducibilidad

# Framework
fastapi==0.115.6
uvicorn[standard]==0.34.0
gunicorn==23.0.0

# Base de datos
sqlalchemy==2.0.36
psycopg2-binary==2.9.10
alembic==1.14.1

# Validaci√≥n y configuraci√≥n
pydantic==2.10.4
pydantic-settings==2.7.1

# Seguridad
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-multipart==0.0.18

# HTTP
httpx==0.28.1

# Utilidades
python-dotenv==1.0.1
```

**¬øPor qu√© `psycopg2-binary` en lugar de `psycopg2`?** El paquete `psycopg2` requiere compilar extensiones C contra las headers de libpq instaladas en el sistema. `psycopg2-binary` incluye una versi√≥n precompilada de libpq. Esto simplifica el Dockerfile y acelera el build. Para producci√≥n de alta escala, algunos equipos prefieren `psycopg2` compilado contra la versi√≥n exacta de libpq del servidor PostgreSQL, pero `psycopg2-binary` es perfectamente v√°lido para la mayor√≠a de casos.

## 5.4 C√≥digo Base del Backend

### Configuraci√≥n centralizada con Pydantic Settings

```python
# backend/app/config.py
from pydantic_settings import BaseSettings
from functools import lru_cache


class Settings(BaseSettings):
    """
    Configuraci√≥n centralizada. Los valores se cargan de variables de entorno.
    Pydantic Settings valida tipos autom√°ticamente.
    """
    # Base de datos
    POSTGRES_HOST: str = "db"
    POSTGRES_PORT: int = 5432
    POSTGRES_USER: str = "appuser"
    POSTGRES_PASSWORD: str  # Obligatorio, sin default
    POSTGRES_DB: str = "appdb"

    # Aplicaci√≥n
    APP_NAME: str = "My App API"
    DEBUG: bool = False
    ALLOWED_ORIGINS: list[str] = ["http://localhost:3000"]

    # Seguridad
    SECRET_KEY: str  # Obligatorio
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30

    @property
    def database_url(self) -> str:
        return (
            f"postgresql://{self.POSTGRES_USER}:{self.POSTGRES_PASSWORD}"
            f"@{self.POSTGRES_HOST}:{self.POSTGRES_PORT}/{self.POSTGRES_DB}"
        )

    @property
    def async_database_url(self) -> str:
        return (
            f"postgresql+asyncpg://{self.POSTGRES_USER}:{self.POSTGRES_PASSWORD}"
            f"@{self.POSTGRES_HOST}:{self.POSTGRES_PORT}/{self.POSTGRES_DB}"
        )

    class Config:
        env_file = ".env"
        case_sensitive = True


@lru_cache
def get_settings() -> Settings:
    """Singleton: la configuraci√≥n se parsea una sola vez."""
    return Settings()
```

### Punto de entrada FastAPI

```python
# backend/app/main.py
from contextlib import asynccontextmanager
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from app.config import get_settings
from app.database import engine, Base
from app.routers import users

settings = get_settings()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Ciclo de vida de la aplicaci√≥n.
    Se ejecuta al arrancar y al apagar.
    """
    # Startup: crear tablas si no existen (solo desarrollo)
    # En producci√≥n, usar Alembic exclusivamente
    if settings.DEBUG:
        async with engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
    yield
    # Shutdown: cerrar conexiones
    await engine.dispose()


app = FastAPI(
    title=settings.APP_NAME,
    docs_url="/docs" if settings.DEBUG else None,  # Desactivar Swagger en prod
    redoc_url="/redoc" if settings.DEBUG else None,
    lifespan=lifespan,
)

# CORS ‚Äî solo necesario si el frontend NO pasa por Nginx proxy
# Con Nginx proxy_pass, CORS no es necesario (mismo origen)
if settings.DEBUG:
    app.add_middleware(
        CORSMiddleware,
        allow_origins=settings.ALLOWED_ORIGINS,
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

# Registrar routers
app.include_router(users.router, prefix="/users", tags=["users"])


@app.get("/health")
async def health_check():
    """Endpoint para healthchecks de Docker y load balancers."""
    return {"status": "healthy"}
```

### Conexi√≥n a la Base de Datos

```python
# backend/app/database.py
from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
from sqlalchemy.orm import DeclarativeBase

from app.config import get_settings

settings = get_settings()

# Engine con pool de conexiones
engine = create_async_engine(
    settings.async_database_url,
    echo=settings.DEBUG,         # Log SQL queries en modo debug
    pool_size=20,                # Conexiones en el pool
    max_overflow=10,             # Conexiones extra permitidas
    pool_timeout=30,             # Segundos esperando una conexi√≥n
    pool_recycle=1800,           # Reciclar conexiones cada 30 min
    pool_pre_ping=True,          # Verificar conexi√≥n antes de usarla
)

# Session factory
AsyncSessionLocal = async_sessionmaker(
    bind=engine,
    class_=AsyncSession,
    expire_on_commit=False,
)


class Base(DeclarativeBase):
    """Clase base para todos los modelos ORM."""
    pass


async def get_db() -> AsyncSession:
    """Dependency injection para obtener sesi√≥n de BD."""
    async with AsyncSessionLocal() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()
```

## 5.5 Dockerfile de Desarrollo

```dockerfile
# ============================================================
# backend/Dockerfile.dev ‚Äî Desarrollo con Hot Reload
# ============================================================
FROM python:3.12-slim

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

# Dependencias del sistema
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        libpq-dev \
        curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Instalar dependencias (incluye herramientas de desarrollo)
COPY requirements.txt requirements-dev.txt ./
RUN pip install --no-cache-dir -r requirements.txt -r requirements-dev.txt

# El c√≥digo se monta como bind mount
EXPOSE 8000

# Uvicorn con --reload para hot reload
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
```

```
# backend/requirements-dev.txt
pytest==8.3.4
pytest-asyncio==0.24.0
httpx==0.28.1
ruff==0.8.6
mypy==1.14.1
debugpy==1.8.11
```

---

# 6. Servicio PostgreSQL

## 6.1 Configuraci√≥n del Servicio

PostgreSQL se configura directamente en `docker-compose.yml` sin Dockerfile propio. La imagen oficial es suficiente para la mayor√≠a de casos.

**Decisiones clave:**

### Persistencia con Named Volume

```yaml
volumes:
  postgres_data:
    driver: local
```

El directorio `/var/lib/postgresql/data` dentro del contenedor es donde PostgreSQL almacena todos los datos (tablas, √≠ndices, WAL). Montamos un named volume aqu√≠. Esto significa que al ejecutar `docker compose down`, los datos persisten. Solo `docker compose down -v` destruye los vol√∫menes.

**Trampa com√∫n:** Si NO montas un volumen, un `docker compose down` seguido de `docker compose up` crea un contenedor PostgreSQL nuevo y vac√≠o. Todos los datos se pierden. Esto es la causa #1 de p√©rdida de datos en equipos que empiezan con Docker.

### Inicializaci√≥n Autom√°tica

La imagen oficial de PostgreSQL ejecuta autom√°ticamente todos los scripts `.sql` y `.sh` en `/docker-entrypoint-initdb.d/` cuando la base de datos se crea por primera vez. Esto solo ocurre si el volumen de datos est√° vac√≠o.

```sql
-- database/init/01-init.sql
-- Este script se ejecuta SOLO en la primera creaci√≥n de la BD

-- Crear extensiones necesarias
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";

-- Crear esquema de la aplicaci√≥n
CREATE SCHEMA IF NOT EXISTS app;

-- Ajustes de rendimiento (override de postgresql.conf)
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '768MB';
ALTER SYSTEM SET maintenance_work_mem = '128MB';
ALTER SYSTEM SET random_page_cost = 1.1;
ALTER SYSTEM SET effective_io_concurrency = 200;
ALTER SYSTEM SET work_mem = '4MB';
ALTER SYSTEM SET max_connections = 100;
```

**Orden de ejecuci√≥n:** Los scripts se ejecutan en orden alfab√©tico. Por eso los prefijamos con n√∫meros (`01-init.sql`, `02-seed.sql`).

### Variables de Entorno Requeridas

```
POSTGRES_USER=appuser         # NO usar "postgres" (superusuario)
POSTGRES_PASSWORD=...         # Contrase√±a fuerte
POSTGRES_DB=appdb             # Nombre de la base de datos
```

**Seguridad:** Creamos un usuario dedicado (`appuser`) en lugar de usar el superusuario `postgres`. El backend se conecta con permisos limitados. Si la aplicaci√≥n es comprometida, el atacante no tiene permisos de superusuario en PostgreSQL.

## 6.2 Script de Backup

```bash
#!/bin/bash
# scripts/backup-db.sh
# Uso: ./scripts/backup-db.sh

set -euo pipefail

TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="./database/backups"
BACKUP_FILE="${BACKUP_DIR}/backup_${TIMESTAMP}.sql.gz"

# Crear directorio si no existe
mkdir -p "${BACKUP_DIR}"

# Dump comprimido usando el contenedor de PostgreSQL
docker compose exec -T db pg_dump \
    -U "${POSTGRES_USER:-appuser}" \
    -d "${POSTGRES_DB:-appdb}" \
    --format=custom \
    --compress=9 \
    --verbose \
    > "${BACKUP_FILE}"

echo "Backup creado: ${BACKUP_FILE}"
echo "Tama√±o: $(du -h ${BACKUP_FILE} | cut -f1)"

# Eliminar backups con m√°s de 7 d√≠as
find "${BACKUP_DIR}" -name "backup_*.sql.gz" -mtime +7 -delete
echo "Backups antiguos eliminados"
```

## 6.3 Restauraci√≥n

```bash
#!/bin/bash
# Restaurar un backup espec√≠fico
docker compose exec -T db pg_restore \
    -U appuser \
    -d appdb \
    --clean \
    --if-exists \
    --verbose \
    < ./database/backups/backup_20260225_120000.sql.gz
```

---

# 7. docker-compose.yml Profesional

## 7.1 Archivo Base

```yaml
# docker-compose.yml
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Archivo base de Docker Compose para el sistema completo
# Se usa combinado con docker-compose.dev.yml o docker-compose.prod.yml
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚îÄ‚îÄ Redes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Dos redes aisladas para segmentaci√≥n de servicios
networks:
  frontend_net:
    driver: bridge
    # El frontend y el backend comparten esta red
  backend_net:
    driver: bridge
    # Solo el backend y la base de datos

# ‚îÄ‚îÄ Vol√∫menes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Named volumes gestionados por Docker
volumes:
  postgres_data:
    driver: local
    # Persistencia de datos PostgreSQL
    # Ubicaci√≥n f√≠sica: /var/lib/docker/volumes/project_postgres_data/_data

# ‚îÄ‚îÄ Servicios ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
services:

  # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
  # ‚ïë  FRONTEND ‚Äî React + Nginx                            ‚ïë
  # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
  frontend:
    build:
      context: ./frontend           # Directorio con el Dockerfile
      dockerfile: Dockerfile        # Dockerfile de producci√≥n por defecto
      args:
        VITE_API_URL: /api          # Se embebe en el bundle de React
    container_name: app-frontend    # Nombre fijo para facilitar referencia
    restart: unless-stopped         # Reinicio autom√°tico excepto parada manual
    ports:
      - "${FRONTEND_PORT:-80}:80"   # Mapeado de puerto con default
    networks:
      - frontend_net                # Solo red frontend
    depends_on:
      backend:
        condition: service_healthy  # Esperar a que backend pase healthcheck
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1",
             "--spider", "http://localhost:80/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 128M              # Nginx usa muy poca memoria
          cpus: "0.25"

  # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
  # ‚ïë  BACKEND ‚Äî FastAPI + Gunicorn/Uvicorn                ‚ïë
  # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: app-backend
    restart: unless-stopped
    # NO exponemos el puerto al host en producci√≥n
    # El backend solo es accesible v√≠a Nginx (frontend_net)
    expose:
      - "8000"                      # Puerto interno, no mapeado al host
    networks:
      - frontend_net                # Para recibir peticiones de Nginx
      - backend_net                 # Para conectar con PostgreSQL
    depends_on:
      db:
        condition: service_healthy  # Esperar a que PostgreSQL est√© listo
    environment:
      # Variables inyectadas desde .env
      - POSTGRES_HOST=db            # Nombre del servicio Docker (DNS interno)
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - SECRET_KEY=${SECRET_KEY}
      - DEBUG=${DEBUG:-false}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s            # Dar tiempo a Gunicorn para iniciar workers
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "1.0"

  # ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
  # ‚ïë  DATABASE ‚Äî PostgreSQL 16                            ‚ïë
  # ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
  db:
    image: postgres:16-alpine       # Alpine = imagen m√°s peque√±a (~80 MB)
    container_name: app-db
    restart: unless-stopped
    # NO usar "ports:" ‚Äî la BD no se expone al host
    expose:
      - "5432"                      # Solo accesible dentro de backend_net
    networks:
      - backend_net                 # SOLO red backend, aislada del frontend
    volumes:
      - postgres_data:/var/lib/postgresql/data          # Datos persistentes
      - ./database/init:/docker-entrypoint-initdb.d     # Scripts de inicio
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      # Optimizaciones de rendimiento
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "1.0"
    # Par√°metros de PostgreSQL inyectados como comando
    command:
      - "postgres"
      - "-c" 
      - "max_connections=100"
      - "-c"
      - "shared_buffers=256MB"
      - "-c"
      - "log_statement=mod"         # Log INSERT/UPDATE/DELETE (no SELECT)
      - "-c"
      - "log_min_duration_statement=200"  # Log queries > 200ms
```

## 7.2 Explicaci√≥n Detallada

### `networks` ‚Äî Segmentaci√≥n de Red

```yaml
networks:
  frontend_net:
    driver: bridge
  backend_net:
    driver: bridge
```

Creamos dos redes bridge. `frontend` pertenece solo a `frontend_net`. `db` pertenece solo a `backend_net`. `backend` pertenece a ambas, actuando como puente controlado. Esto implementa el principio de **menor privilegio a nivel de red**: un contenedor frontend comprometido no puede alcanzar PostgreSQL.

### `depends_on` con `condition: service_healthy`

```yaml
depends_on:
  db:
    condition: service_healthy
```

Sin `condition: service_healthy`, `depends_on` solo espera a que el contenedor ARRANQUE (estado `running`), no a que el servicio est√© LISTO. PostgreSQL puede tardar 5-15 segundos en inicializar. Sin healthcheck, FastAPI intenta conectarse a un PostgreSQL que a√∫n no acepta conexiones y falla con `ConnectionRefused`.

El healthcheck de PostgreSQL usa `pg_isready`, una herramienta incluida en la imagen oficial que verifica si el servidor acepta conexiones. Solo cuando retorna exitosamente, Docker considera el servicio `healthy` y permite que los servicios dependientes arranquen.

### `expose` vs `ports`

```yaml
# Backend
expose:
  - "8000"    # Puerto visible SOLO dentro de las redes Docker

# Frontend
ports:
  - "80:80"   # Puerto mapeado al HOST (accesible desde Internet)
```

`expose` documenta el puerto interno y lo hace accesible entre contenedores en la misma red, pero NO lo mapea al host. `ports` mapea `host:contenedor` y lo hace accesible desde fuera de Docker.

**Regla de producci√≥n:** Solo el frontend (Nginx) debe usar `ports`. El backend y la base de datos usan `expose` exclusivamente. Si necesitas acceso temporal a PostgreSQL para debugging, usa `docker compose exec db psql` en lugar de exponer el puerto.

### `restart: unless-stopped`

El contenedor se reinicia autom√°ticamente ante ca√≠das, incluido un reinicio del servidor host. Pero si un operador ejecuta `docker compose stop` para mantenimiento, el contenedor NO se reinicia autom√°ticamente hasta que se ejecute `docker compose start`.

### `deploy.resources.limits`

```yaml
deploy:
  resources:
    limits:
      memory: 512M
      cpus: "1.0"
```

Limita los recursos que el contenedor puede consumir. Esto previene que un servicio con memory leak consuma toda la RAM del host y mate a los dem√°s. En producci√≥n, estos l√≠mites son obligatorios.

## 7.3 Override de Desarrollo

```yaml
# docker-compose.dev.yml
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Override para desarrollo local
# Uso: docker compose -f docker-compose.yml -f docker-compose.dev.yml up
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev    # Dockerfile de desarrollo
    ports:
      - "5173:5173"                 # Puerto de Vite dev server
    volumes:
      - ./frontend/src:/app/src     # Hot reload del c√≥digo
      - ./frontend/public:/app/public
      - /app/node_modules           # Excluir node_modules del bind mount
    environment:
      - NODE_ENV=development
      - VITE_API_URL=http://localhost:8000  # En dev, sin proxy Nginx

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    ports:
      - "8000:8000"                 # Exponer backend directamente en dev
    volumes:
      - ./backend/app:/app/app      # Hot reload del c√≥digo Python
      - ./backend/tests:/app/tests
      - ./backend/alembic:/app/alembic
    environment:
      - DEBUG=true
      - ALLOWED_ORIGINS=["http://localhost:5173"]

  db:
    ports:
      - "5432:5432"                 # Exponer PostgreSQL para herramientas locales
                                    # (pgAdmin, DBeaver, etc.)
```

**`/app/node_modules` como volumen an√≥nimo:**

```yaml
volumes:
  - ./frontend/src:/app/src
  - /app/node_modules           # ‚Üê Volumen an√≥nimo
```

Esto es un patr√≥n importante. El bind mount `./frontend/src:/app/src` monta el c√≥digo del host. Pero si el host tiene un directorio `node_modules` diferente (o vac√≠o), pisar√≠a el `node_modules` instalado dentro del contenedor. El volumen an√≥nimo `/app/node_modules` "protege" ese directorio: Docker lo gestiona internamente y no se ve afectado por el bind mount del host.

## 7.4 Override de Producci√≥n

```yaml
# docker-compose.prod.yml
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Override para producci√≥n
# Uso: docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile        # Multi-stage con Nginx
      args:
        VITE_API_URL: /api
    ports:
      - "80:80"
      - "443:443"                   # Si se configura TLS en Nginx

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile        # Con Gunicorn
    # Sin ports: ‚Äî solo accesible v√≠a Nginx
    environment:
      - DEBUG=false

  db:
    # Sin ports: ‚Äî aislado completamente
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}  # Contrase√±a fuerte de producci√≥n
```

## 7.5 Archivo .env

```bash
# .env ‚Äî Variables de entorno
# NUNCA commitear este archivo. Usar .env.example como template.

# ‚îÄ‚îÄ PostgreSQL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
POSTGRES_USER=appuser
POSTGRES_PASSWORD=S3cur3_P@ssw0rd_Ch4ng3_M3!
POSTGRES_DB=appdb

# ‚îÄ‚îÄ Backend ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
SECRET_KEY=your-256-bit-secret-key-here-generate-with-openssl
DEBUG=false

# ‚îÄ‚îÄ Frontend ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FRONTEND_PORT=80

# ‚îÄ‚îÄ Compose ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
COMPOSE_PROJECT_NAME=myapp
```

```bash
# .env.example ‚Äî Template (se commitea al repositorio)
POSTGRES_USER=appuser
POSTGRES_PASSWORD=CHANGE_ME
POSTGRES_DB=appdb
SECRET_KEY=CHANGE_ME
DEBUG=false
FRONTEND_PORT=80
COMPOSE_PROJECT_NAME=myapp
```

---

# 8. Comunicaci√≥n entre Servicios

## 8.1 DNS Interno de Docker

Docker Compose incluye un servidor DNS embebido (128.0.0.11) que resuelve los nombres de servicio definidos en `docker-compose.yml` a las direcciones IP de los contenedores.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Docker DNS (128.0.0.11)                    ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  "frontend"  ‚Üí 172.18.0.2                  ‚îÇ
‚îÇ  "backend"   ‚Üí 172.18.0.3                  ‚îÇ
‚îÇ  "db"        ‚Üí 172.18.0.4                  ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  Tambi√©n resuelve:                          ‚îÇ
‚îÇ  "app-frontend"  ‚Üí 172.18.0.2  (container) ‚îÇ
‚îÇ  "app-backend"   ‚Üí 172.18.0.3  (container) ‚îÇ
‚îÇ  "app-db"        ‚Üí 172.18.0.4  (container) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Cuando FastAPI necesita conectarse a PostgreSQL, usa `db` como hostname:

```
postgresql://appuser:password@db:5432/appdb
                               ^^
                    Nombre del servicio en docker-compose.yml
```

Docker resuelve `db` a la IP del contenedor PostgreSQL. Esto funciona autom√°ticamente sin ninguna configuraci√≥n adicional, siempre que ambos contenedores est√©n en la misma red Docker.

**Punto cr√≠tico:** El DNS solo resuelve nombres dentro de la misma red Docker. Como `frontend` y `db` est√°n en redes diferentes (`frontend_net` y `backend_net`), el frontend NO puede resolver `db`. Esto es intencional.

## 8.2 Conexi√≥n FastAPI ‚Üí PostgreSQL

La conexi√≥n usa SQLAlchemy con el connection string que referencia el servicio `db`:

```python
# La variable POSTGRES_HOST=db se define en docker-compose.yml
DATABASE_URL = "postgresql://appuser:password@db:5432/appdb"
```

**Pool de conexiones:** SQLAlchemy mantiene un pool de conexiones persistentes. Esto evita el overhead de crear una nueva conexi√≥n TCP + handshake SSL + autenticaci√≥n PostgreSQL en cada petici√≥n HTTP. Con `pool_size=20` y `max_overflow=10`, el backend puede manejar hasta 30 conexiones simult√°neas.

**`pool_pre_ping=True`:** Antes de entregar una conexi√≥n del pool a la aplicaci√≥n, SQLAlchemy env√≠a un `SELECT 1` para verificar que la conexi√≥n sigue viva. Esto previene el error "connection reset by peer" cuando PostgreSQL cierra conexiones idle.

## 8.3 Conexi√≥n React ‚Üí FastAPI

### En Producci√≥n (con Nginx proxy)

```
Navegador                      Docker
   ‚îÇ                             ‚îÇ
   ‚îÇ  GET /api/users             ‚îÇ
   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Nginx (frontend:80)
   ‚îÇ                             ‚îÇ    ‚îÇ
   ‚îÇ                             ‚îÇ    ‚îÇ proxy_pass http://backend:8000/
   ‚îÇ                             ‚îÇ    ‚îÇ
   ‚îÇ                             ‚îÇ    ‚ñº
   ‚îÇ                             ‚îÇ FastAPI (backend:8000)
   ‚îÇ                             ‚îÇ    ‚îÇ
   ‚îÇ  HTTP 200 [{...}]          ‚îÇ    ‚îÇ
   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îÇ
```

React hace `fetch("/api/users")`. Nginx intercepta la ruta `/api/*` y reenv√≠a la petici√≥n a `http://backend:8000`. Como la petici√≥n va al mismo dominio y puerto que sirvi√≥ la p√°gina, **no hay problema de CORS**.

Configuraci√≥n del cliente HTTP en React:

```javascript
// frontend/src/services/api.js
const API_BASE_URL = import.meta.env.VITE_API_URL || "/api";

export async function fetchFromAPI(endpoint, options = {}) {
  const url = `${API_BASE_URL}${endpoint}`;
  
  const response = await fetch(url, {
    headers: {
      "Content-Type": "application/json",
      ...options.headers,
    },
    ...options,
  });

  if (!response.ok) {
    throw new Error(`API Error: ${response.status}`);
  }

  return response.json();
}

// Uso:
// fetchFromAPI("/users")         ‚Üí  GET /api/users
// fetchFromAPI("/users", {
//   method: "POST",
//   body: JSON.stringify(data),
// })
```

### En Desarrollo (sin Nginx proxy)

En desarrollo, React se ejecuta en Vite dev server (puerto 5173) y el backend en Uvicorn (puerto 8000). Son dominios diferentes (`localhost:5173` vs `localhost:8000`), por lo que **CORS es obligatorio**.

```python
# backend/app/main.py ‚Äî Solo en modo DEBUG
if settings.DEBUG:
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["http://localhost:5173"],  # Origen exacto de Vite
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
```

Y en React:

```javascript
// En desarrollo, VITE_API_URL=http://localhost:8000
// Definido en docker-compose.dev.yml
const API_BASE_URL = import.meta.env.VITE_API_URL || "/api";
```

## 8.4 Manejo de CORS: Gu√≠a Definitiva

CORS (Cross-Origin Resource Sharing) es un mecanismo de seguridad del navegador que bloquea peticiones entre diferentes or√≠genes. Un "origen" se compone de protocolo + dominio + puerto.

```
Mismo origen (CORS no aplica):
  http://miapp.com/         (p√°gina)
  http://miapp.com/api/users (API)
  ‚Üí Mismo protocolo, dominio y puerto

Diferente origen (CORS requerido):
  http://localhost:5173     (React dev server)
  http://localhost:8000     (FastAPI)
  ‚Üí Mismo protocolo y dominio, DIFERENTE puerto
```

**La regla de oro:** En producci√≥n, configura Nginx como proxy para que frontend y API est√©n en el mismo origen. Esto elimina la necesidad de CORS por completo. CORS solo debe habilitarse en desarrollo.

**Errores comunes:**
- `allow_origins=["*"]` en producci√≥n: Esto permite que CUALQUIER sitio web haga peticiones a tu API. Un atacante podr√≠a hacer que el navegador de un usuario env√≠e peticiones autenticadas a tu API desde un sitio malicioso.
- Olvidar `allow_credentials=True` cuando usas cookies o tokens en headers.
- No incluir los headers `Authorization` en `allow_headers`.

---

# 9. Modo Desarrollo vs Producci√≥n

## 9.1 Comparaci√≥n Completa

| Aspecto | Desarrollo | Producci√≥n |
|---------|------------|------------|
| **Frontend server** | Vite dev server (HMR) | Nginx sirve build est√°tico |
| **Backend server** | Uvicorn con `--reload` | Gunicorn + Uvicorn workers |
| **C√≥digo** | Bind mount (edici√≥n en vivo) | COPY en imagen (inmutable) |
| **Debug** | Habilitado, Swagger visible | Deshabilitado, sin docs |
| **CORS** | Habilitado (puertos diferentes) | No necesario (Nginx proxy) |
| **DB acceso** | Puerto 5432 expuesto al host | Sin exposici√≥n al host |
| **Logs SQL** | `echo=True` (todas las queries) | Solo queries > 200ms |
| **Restart policy** | `no` (manual) | `unless-stopped` |
| **Recursos** | Sin l√≠mites | CPU/RAM limitados |
| **Im√°genes** | Dockerfile.dev (herramientas) | Dockerfile (multi-stage, slim) |
| **Variables** | DEBUG=true | DEBUG=false |

## 9.2 Comandos de Arranque

```bash
# ‚îÄ‚îÄ Desarrollo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
docker compose -f docker-compose.yml -f docker-compose.dev.yml up --build

# ‚îÄ‚îÄ Producci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --build

# ‚îÄ‚îÄ Detener (preservando datos) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
docker compose down

# ‚îÄ‚îÄ Detener Y eliminar vol√∫menes (DESTRUYE DATOS) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
docker compose down -v
```

## 9.3 Makefile para Simplificar

```makefile
# Makefile
.PHONY: dev prod down logs backup migrate test

# ‚îÄ‚îÄ Desarrollo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
dev:
	docker compose -f docker-compose.yml -f docker-compose.dev.yml up --build

dev-detached:
	docker compose -f docker-compose.yml -f docker-compose.dev.yml up --build -d

# ‚îÄ‚îÄ Producci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
prod:
	docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --build

# ‚îÄ‚îÄ Gesti√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
down:
	docker compose down

destroy:
	docker compose down -v --rmi all

restart:
	docker compose restart

logs:
	docker compose logs -f --tail=100

logs-backend:
	docker compose logs -f backend

logs-db:
	docker compose logs -f db

# ‚îÄ‚îÄ Base de datos ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
migrate:
	docker compose exec backend alembic upgrade head

migrate-create:
	docker compose exec backend alembic revision --autogenerate -m "$(msg)"

backup:
	./scripts/backup-db.sh

psql:
	docker compose exec db psql -U $(POSTGRES_USER) -d $(POSTGRES_DB)

# ‚îÄ‚îÄ Testing ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
test:
	docker compose exec backend pytest -v

test-coverage:
	docker compose exec backend pytest --cov=app --cov-report=html

# ‚îÄ‚îÄ Utilidades ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
shell-backend:
	docker compose exec backend bash

shell-frontend:
	docker compose exec frontend sh

status:
	docker compose ps
	@echo ""
	@docker compose top
```

---

# 10. Seguridad y Buenas Pr√°cticas

## 10.1 Variables Secretas

**Nunca hardcodear credenciales en `docker-compose.yml` ni en Dockerfiles.**

```yaml
# ‚ùå NUNCA hacer esto
environment:
  POSTGRES_PASSWORD: mi_password_insegura

# ‚úÖ Referencia a .env
environment:
  POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
```

Para producci√≥n avanzada, usar Docker Secrets o un vault externo (HashiCorp Vault, AWS Secrets Manager):

```yaml
# docker-compose.prod.yml con secrets (Docker Swarm o workaround)
secrets:
  db_password:
    file: ./secrets/db_password.txt

services:
  db:
    secrets:
      - db_password
    environment:
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
```

## 10.2 Usuarios No Root

Todos los Dockerfiles deben crear y usar un usuario sin privilegios:

```dockerfile
# Python
RUN groupadd -r appuser && useradd -r -g appuser appuser
USER appuser

# Alpine/Node
RUN addgroup -S appgroup && adduser -S appuser -G appgroup
USER appuser

# Nginx (imagen oficial ya tiene usuario 'nginx')
USER nginx
```

**¬øPor qu√© importa?** Si un atacante explota una vulnerabilidad en la aplicaci√≥n y obtiene ejecuci√≥n de c√≥digo dentro del contenedor, con usuario root podr√≠a:
- Montar el filesystem del host (si tiene capabilities)
- Modificar binarios del sistema
- Escalar privilegios

Con usuario no-root, el da√±o es limitado al contexto de ese usuario.

## 10.3 Reducci√≥n de Superficie de Ataque

```dockerfile
# Usar im√°genes slim/alpine (no full)
FROM python:3.12-slim    # ~150 MB vs ~1 GB de python:3.12
FROM node:20-alpine      # ~130 MB vs ~1 GB de node:20
FROM postgres:16-alpine  # ~80 MB vs ~400 MB de postgres:16

# Eliminar cach√© de paquetes
RUN apt-get update && \
    apt-get install -y --no-install-recommends paquete && \
    rm -rf /var/lib/apt/lists/*

# No instalar herramientas de debug en producci√≥n
# (curl se necesita para healthcheck, pero nada m√°s)
```

## 10.4 No Exponer la Base de Datos

```yaml
# ‚ùå NUNCA en producci√≥n
db:
  ports:
    - "5432:5432"    # Accesible desde Internet

# ‚úÖ Solo accesible dentro de Docker
db:
  expose:
    - "5432"         # Solo contenedores en la misma red
```

Si necesitas acceso de emergencia a PostgreSQL en producci√≥n:

```bash
# Usar exec en lugar de exponer puertos
docker compose exec db psql -U appuser -d appdb

# O crear un t√∫nel SSH temporal
ssh -L 5432:localhost:5432 user@production-server
```

## 10.5 Escaneo de Vulnerabilidades

```bash
# Escanear imagen con Docker Scout
docker scout cves app-backend:latest

# Escanear con Trivy (herramienta de Aqua Security)
docker run --rm \
    -v /var/run/docker.sock:/var/run/docker.sock \
    aquasec/trivy image app-backend:latest
```

## 10.6 .dockerignore Completo

```
# .dockerignore global
.git
.gitignore
.env
.env.*
*.md
LICENSE
docker-compose*.yml
.vscode
.idea
__pycache__
*.pyc
.pytest_cache
.mypy_cache
node_modules
dist
build
coverage
.coverage
*.log
```

---

# 11. Automatizaci√≥n y DevOps

## 11.1 Comandos Esenciales de Docker Compose

```bash
# ‚îÄ‚îÄ Ciclo de vida ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
docker compose up                     # Arrancar todos los servicios
docker compose up -d                  # Arrancar en background
docker compose up --build             # Reconstruir im√°genes antes de arrancar
docker compose down                   # Parar y eliminar contenedores
docker compose down -v                # + eliminar vol√∫menes (DATOS)
docker compose down --rmi all         # + eliminar im√°genes
docker compose restart                # Reiniciar todos
docker compose restart backend        # Reiniciar solo uno

# ‚îÄ‚îÄ Observaci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
docker compose ps                     # Estado de servicios
docker compose logs -f                # Logs en tiempo real
docker compose logs -f backend        # Logs de un servicio
docker compose logs --tail=50 backend # √öltimas 50 l√≠neas
docker compose top                    # Procesos por contenedor
docker compose stats                  # Uso de recursos en vivo

# ‚îÄ‚îÄ Ejecuci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
docker compose exec backend bash      # Shell interactivo
docker compose exec db psql -U appuser -d appdb  # PostgreSQL CLI
docker compose run --rm backend pytest  # Ejecutar comando y eliminar contenedor

# ‚îÄ‚îÄ Build ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
docker compose build                  # Build de todas las im√°genes
docker compose build --no-cache       # Build limpio (sin cach√©)
docker compose build backend          # Build de un solo servicio

# ‚îÄ‚îÄ Escalado ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
docker compose up -d --scale backend=3  # 3 instancias del backend
```

## 11.2 Profiles de Compose

Los profiles permiten definir servicios opcionales que solo arrancan cuando se activan:

```yaml
# En docker-compose.yml
services:
  # Servicios core (siempre arrancan)
  frontend:
    # ...
  backend:
    # ...
  db:
    # ...

  # Servicios opcionales
  pgadmin:
    image: dpage/pgadmin4:latest
    profiles: ["debug"]           # Solo arranca con profile "debug"
    ports:
      - "5050:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    networks:
      - backend_net

  redis:
    image: redis:7-alpine
    profiles: ["cache"]           # Solo arranca con profile "cache"
    expose:
      - "6379"
    networks:
      - backend_net

  mailhog:
    image: mailhog/mailhog
    profiles: ["debug"]
    ports:
      - "1025:1025"
      - "8025:8025"
    networks:
      - backend_net
```

```bash
# Arrancar solo servicios core
docker compose up -d

# Arrancar core + herramientas de debug
docker compose --profile debug up -d

# Arrancar core + cach√©
docker compose --profile cache up -d

# Arrancar todo
docker compose --profile debug --profile cache up -d
```

## 11.3 Script de Arranque Inteligente

```bash
#!/bin/bash
# scripts/start-dev.sh

set -euo pipefail

# Colores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

echo -e "${GREEN}üöÄ Iniciando entorno de desarrollo...${NC}"

# Verificar que Docker est√° corriendo
if ! docker info > /dev/null 2>&1; then
    echo -e "${RED}‚ùå Docker no est√° corriendo. In√≠cialo primero.${NC}"
    exit 1
fi

# Verificar que .env existe
if [ ! -f .env ]; then
    echo -e "${YELLOW}‚ö†Ô∏è  Archivo .env no encontrado. Copiando .env.example...${NC}"
    cp .env.example .env
    echo -e "${YELLOW}   ‚Üí Edita .env con tus valores antes de continuar.${NC}"
    exit 1
fi

# Verificar que los puertos no est√°n ocupados
for port in 5173 8000 5432; do
    if lsof -Pi :$port -sTCP:LISTEN -t > /dev/null 2>&1; then
        echo -e "${RED}‚ùå Puerto $port ya est√° en uso.${NC}"
        exit 1
    fi
done

# Construir y arrancar
echo -e "${GREEN}üì¶ Construyendo im√°genes...${NC}"
docker compose -f docker-compose.yml -f docker-compose.dev.yml build

echo -e "${GREEN}üèóÔ∏è  Levantando servicios...${NC}"
docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d

# Esperar a que los servicios est√©n healthy
echo -e "${YELLOW}‚è≥ Esperando a que los servicios est√©n listos...${NC}"
timeout 120 bash -c 'until docker compose ps | grep -q "healthy"; do sleep 2; done'

# Ejecutar migraciones
echo -e "${GREEN}üóÉÔ∏è  Ejecutando migraciones...${NC}"
docker compose exec -T backend alembic upgrade head

echo ""
echo -e "${GREEN}‚úÖ Entorno de desarrollo listo!${NC}"
echo -e "   Frontend: http://localhost:5173"
echo -e "   Backend:  http://localhost:8000"
echo -e "   API Docs: http://localhost:8000/docs"
echo -e "   DB:       localhost:5432"
echo ""
echo -e "   Logs: docker compose logs -f"
echo -e "   Parar: docker compose down"
```

## 11.4 CI/CD B√°sico con GitHub Actions

```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository }}

jobs:
  # ‚îÄ‚îÄ Tests ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Create .env for testing
        run: |
          cat > .env << EOF
          POSTGRES_USER=testuser
          POSTGRES_PASSWORD=testpassword
          POSTGRES_DB=testdb
          SECRET_KEY=test-secret-key-not-for-production
          DEBUG=true
          EOF

      - name: Build and start services
        run: |
          docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d --build
          docker compose exec -T backend alembic upgrade head

      - name: Run backend tests
        run: docker compose exec -T backend pytest -v --tb=short

      - name: Run frontend tests
        run: docker compose exec -T frontend npm test -- --run

      - name: Cleanup
        if: always()
        run: docker compose down -v

  # ‚îÄ‚îÄ Build y Push de im√°genes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v4

      - name: Login to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Backend
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: true
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}-backend:latest

      - name: Build and push Frontend
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          push: true
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}-frontend:latest

  # ‚îÄ‚îÄ Deploy a VPS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Deploy via SSH
        uses: appleboy/ssh-action@v1
        with:
          host: ${{ secrets.VPS_HOST }}
          username: ${{ secrets.VPS_USER }}
          key: ${{ secrets.VPS_SSH_KEY }}
          script: |
            cd /opt/myapp
            git pull origin main
            docker compose -f docker-compose.yml -f docker-compose.prod.yml pull
            docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d
            docker image prune -f
```

## 11.5 Despliegue en VPS

### Preparaci√≥n del servidor

```bash
# En el VPS (Ubuntu 24.04)
# 1. Instalar Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# 2. Instalar Docker Compose plugin
sudo apt-get install docker-compose-plugin

# 3. Configurar firewall
sudo ufw allow 22/tcp    # SSH
sudo ufw allow 80/tcp    # HTTP
sudo ufw allow 443/tcp   # HTTPS
sudo ufw enable

# 4. Clonar repositorio
git clone https://github.com/user/myapp.git /opt/myapp
cd /opt/myapp

# 5. Configurar .env de producci√≥n
cp .env.example .env
nano .env  # Editar con credenciales de producci√≥n

# 6. Arrancar
docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d --build
```

---

# 12. Problemas Reales y Troubleshooting

## 12.1 Contenedores que No Arrancan

### S√≠ntoma: El contenedor se reinicia en bucle

```bash
# Diagn√≥stico
docker compose ps                    # Ver√°s "Restarting" o "Exit(1)"
docker compose logs backend          # Ver el error espec√≠fico
```

**Causas comunes:**
- Falta una variable de entorno requerida (`SECRET_KEY`, `POSTGRES_PASSWORD`)
- El archivo `main.py` tiene un import error
- Puerto ya ocupado por otro proceso

```bash
# Verificar variables
docker compose exec backend env | grep POSTGRES

# Verificar puertos
sudo lsof -i :8000
```

### S√≠ntoma: `ModuleNotFoundError` en el backend

El Dockerfile no instal√≥ las dependencias correctamente, o el bind mount pis√≥ el directorio de dependencias.

```bash
# Reconstruir sin cach√©
docker compose build --no-cache backend
```

## 12.2 Problemas de Red

### S√≠ntoma: `Connection refused` entre servicios

```
sqlalchemy.exc.OperationalError:
  could not connect to server: Connection refused
  Is the server running on host "db" (172.18.0.4) and
  accepting TCP/IP connections on port 5432?
```

**Causas y soluciones:**

1. **PostgreSQL a√∫n no est√° listo.** El healthcheck con `condition: service_healthy` deber√≠a prevenir esto. Si no lo usas, el backend intenta conectar antes de que PostgreSQL est√© inicializado.

2. **Los servicios est√°n en redes diferentes.** Verifica que backend y db comparten `backend_net`.

3. **El hostname es incorrecto.** Debe ser el nombre del servicio en `docker-compose.yml` (`db`), no `localhost` ni una IP hardcodeada.

```bash
# Verificar conectividad desde el backend
docker compose exec backend ping db
docker compose exec backend curl -v telnet://db:5432

# Verificar redes
docker network ls
docker network inspect myapp_backend_net
```

### S√≠ntoma: Frontend no puede alcanzar el backend

```
GET http://localhost:8000/api/users ‚Üí ERR_CONNECTION_REFUSED
```

**En desarrollo:** Verificar que el backend expone el puerto (`ports: "8000:8000"`).

**En producci√≥n:** El frontend no debe llamar a `localhost:8000`. Debe llamar a `/api/users` (ruta relativa) y Nginx hace el proxy. Verificar que `VITE_API_URL=/api` est√° configurado correctamente en build time.

## 12.3 Race Conditions con la Base de Datos

### El problema cl√°sico

```
backend_1  | sqlalchemy.exc.OperationalError: FATAL:
backend_1  |   database "appdb" does not exist
```

FastAPI arranca antes de que PostgreSQL haya terminado de crear la base de datos. Aunque `depends_on` garantiza que el contenedor de PostgreSQL se inicia primero, no garantiza que el servicio PostgreSQL dentro del contenedor est√© listo.

### Soluci√≥n definitiva: healthcheck + depends_on condition

```yaml
db:
  healthcheck:
    test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
    interval: 5s
    timeout: 5s
    retries: 10
    start_period: 30s

backend:
  depends_on:
    db:
      condition: service_healthy
```

### Soluci√≥n complementaria: retry en la aplicaci√≥n

```python
# backend/app/database.py
import time
from sqlalchemy import create_engine
from sqlalchemy.exc import OperationalError

def create_engine_with_retry(url, max_retries=5, delay=2):
    """Intenta conectar con reintentos exponenciales."""
    for attempt in range(max_retries):
        try:
            engine = create_engine(url)
            # Verificar conexi√≥n
            with engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            return engine
        except OperationalError:
            if attempt < max_retries - 1:
                wait = delay * (2 ** attempt)  # Backoff exponencial
                print(f"DB no disponible. Reintentando en {wait}s...")
                time.sleep(wait)
            else:
                raise
```

## 12.4 Migraciones Fallidas

### Problema: Alembic no puede conectar a la BD

```bash
# Ejecutar migraciones manualmente
docker compose exec backend alembic upgrade head

# Si falla, verificar la URL de conexi√≥n
docker compose exec backend python -c "
from app.config import get_settings
print(get_settings().database_url)
"
```

### Problema: Conflicto de migraciones

Dos desarrolladores crearon migraciones en paralelo, generando dos "heads" en el historial de Alembic.

```bash
# Ver el historial
docker compose exec backend alembic history

# Merge de heads
docker compose exec backend alembic merge heads -m "merge branches"
```

### Problema: La migraci√≥n es irreversible

```bash
# Ver estado actual
docker compose exec backend alembic current

# Downgrade a una revisi√≥n espec√≠fica
docker compose exec backend alembic downgrade abc123

# Downgrade un paso
docker compose exec backend alembic downgrade -1
```

## 12.5 Errores Comunes de Principiantes

### 1. "Mis cambios no se reflejan"

**Causa:** No se reconstruy√≥ la imagen despu√©s de cambiar el Dockerfile o las dependencias.

```bash
# SIEMPRE usar --build al cambiar Dockerfiles o requirements
docker compose up --build
```

### 2. "El contenedor tiene datos viejos de la BD"

**Causa:** El volumen persiste los datos. Los scripts de `initdb.d` solo se ejecutan cuando el volumen est√° vac√≠o.

```bash
# Para reiniciar la BD desde cero
docker compose down -v    # ¬°Elimina TODOS los vol√∫menes!
docker compose up --build
```

### 3. "node_modules da errores de m√≥dulos nativos"

**Causa:** Se copi√≥ `node_modules` del host (macOS/Windows) al contenedor (Linux). Las extensiones nativas son incompatibles.

**Soluci√≥n:** Agregar `node_modules` a `.dockerignore` y al volumen an√≥nimo:

```yaml
volumes:
  - ./frontend:/app
  - /app/node_modules    # Protege node_modules del bind mount
```

### 4. "Los logs no aparecen"

**Causa para Python:** Falta `PYTHONUNBUFFERED=1`.  
**Causa para Node:** La aplicaci√≥n escribe a un archivo en lugar de stdout.

**Regla:** En contenedores, SIEMPRE escribir logs a stdout/stderr. Docker los captura autom√°ticamente. No usar archivos de log dentro del contenedor.

### 5. "El build tarda una eternidad"

**Causa:** El orden de instrucciones en el Dockerfile invalida el cach√© frecuentemente.

```dockerfile
# ‚ùå Mal: cualquier cambio en el c√≥digo invalida la cach√© de dependencias
COPY . .
RUN pip install -r requirements.txt

# ‚úÖ Bien: las dependencias se cachean independientemente del c√≥digo
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
```

### 6. "Permission denied en vol√∫menes"

**Causa:** El usuario dentro del contenedor (e.g., UID 1000) no tiene permisos sobre los archivos montados del host.

```bash
# Verificar UIDs
docker compose exec backend id
# uid=1000(appuser) gid=1000(appuser)

ls -la ./backend/app/
# Si los archivos son de root en el host, el contenedor no puede leerlos
```

**Soluci√≥n:** Asegurar que el UID del usuario en el contenedor coincide con el UID del usuario del host, o usar `chown` en el Dockerfile.

### 7. "Disco lleno"

Docker acumula im√°genes, contenedores detenidos y vol√∫menes hu√©rfanos.

```bash
# Ver uso de disco
docker system df

# Limpiar TODO lo no utilizado (im√°genes, contenedores, redes, cach√©)
docker system prune -a --volumes

# Limpiar solo im√°genes sin usar
docker image prune -a

# Limpiar solo vol√∫menes hu√©rfanos
docker volume prune
```

---

# Ap√©ndice A: Referencia R√°pida de Comandos

```bash
# ‚îÄ‚îÄ Desarrollo ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
make dev                              # Arrancar desarrollo
make logs                             # Ver todos los logs
make logs-backend                     # Ver logs del backend
make psql                             # Conectar a PostgreSQL
make migrate                          # Ejecutar migraciones
make test                             # Ejecutar tests

# ‚îÄ‚îÄ Producci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
make prod                             # Arrancar producci√≥n
make backup                           # Backup de la BD

# ‚îÄ‚îÄ Limpieza ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
make down                             # Parar servicios
make destroy                          # Eliminar todo
docker system prune -a                # Liberar disco
```

# Ap√©ndice B: Checklist Pre-Deploy

```
‚ñ° .env configurado con credenciales de producci√≥n
‚ñ° .env NO est√° en el repositorio (verificar .gitignore)
‚ñ° SECRET_KEY generado con: openssl rand -hex 32
‚ñ° POSTGRES_PASSWORD es fuerte (20+ caracteres aleatorios)
‚ñ° DEBUG=false
‚ñ° Swagger/ReDoc desactivado (docs_url=None)
‚ñ° CORS configurado con or√≠genes espec√≠ficos (no "*")
‚ñ° PostgreSQL NO expone puertos al host
‚ñ° Im√°genes construidas con multi-stage build
‚ñ° Usuarios no-root en todos los contenedores
‚ñ° Healthchecks configurados en todos los servicios
‚ñ° Restart policy: unless-stopped
‚ñ° L√≠mites de recursos (CPU/RAM) definidos
‚ñ° Vol√∫menes de datos con named volumes
‚ñ° Backups automatizados
‚ñ° Logs van a stdout/stderr
‚ñ° Firewall configurado (solo 80/443 abiertos)
‚ñ° TLS/SSL configurado (Let's Encrypt + Nginx)
```
